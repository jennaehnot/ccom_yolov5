{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Validation Process\n",
    "### Running inference on video (or multiple videos) of a buoy being reeled towards the camera. The video has been exported to frames in the naming convention of 'frame_xxxxx.png'. A csv file contains the frame numbers and the respectiver distance to the buoy, as announced in the video. These numbers are then interpolated to assign a distance for each frame.\n",
    "### The images are then passed to YOLO where they are downsampled to the specified sizes and inference is run on them. The results are saved, and compare to the hand annotated images, and if the boundary boxes match, pthey are deemed 'correct'. The confidence of the correct values are plotted as a function of distance. which is interpolated from the video. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here's the file structure the the annotated videos should be in for the script to work as intended\n",
    "```\n",
    "annotated_videos/\n",
    "    -video1/\n",
    "        -frames_dist_coor.csv # csv of frames and the cooresponding distances\n",
    "        -images/\n",
    "            -frame_00001.png\n",
    "            -frame_00002.png\n",
    "            -..... \n",
    "        -labels/ # groundtruth/hand annotated labels\n",
    "            -frame_00001.txt\n",
    "            -frame_00002.txt\n",
    "            -frame_...\n",
    "        -inference/ # where results will be saved\n",
    "    -video2/\n",
    "```\n",
    "        \n",
    "Running the cells below will populate the inference folder like so:\n",
    "```\n",
    "        -inference/\n",
    "            -imgsz1/\n",
    "                -frame_00001.png #inference results w bb_box\n",
    "                -frame_XXXX\n",
    "                -frame_...\n",
    "                -inference_results.json\n",
    "                -validated_results.json\n",
    "            -imgsz2/\n",
    "                -frame...\n",
    "                -inference_results.json\n",
    "                -validated_results.json\n",
    "```        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import val\n",
    "import custom_funcs as cf\n",
    "import matplotlib.pyplot as plt\n",
    "import os, torch, cv2, shutil, json, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.metrics import bbox_iou\n",
    "import utils.general as gen\n",
    "from matplotlib.lines import Line2D\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare all your paths and img sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to yolo folder and weights of choice\n",
    "dhufish_path ='/home/field/jennaDir/ccom_yolov5'\n",
    "vm_path = '/home/jennaehnot/Desktop/ccom_yolov5'\n",
    "\n",
    "weights_path= 'ccom_yolov5/model_testing/model3_4_best.pt'\n",
    "yolo_dir = dhufish_path\n",
    "\n",
    "# path to annotated videos like shown above\n",
    "annotated_dir = '/home/jennaehnot/Desktop/annotated_videos'\n",
    "buoy_vids = ['mooringBall_115cmH', 'lobsterPot_140cmH','redBall_150cmH']\n",
    "plot_titles = ['Mooring Ball', 'Lobster Pot', 'Red Mooring Ball'] # for plot titles while saving\n",
    "plot_save_name = '_conf_by_dist_by_imgsz.png' # will be added on to buoy_vid name\n",
    "\n",
    "#img sizes to run inference at\n",
    "img_sz = [640, 960,1280, 1600, 1920]\n",
    "images = 'images'\n",
    "labels = 'labels'\n",
    "inference = 'inference'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Running inference on all videos at all img sizes and saving results to json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model !\n",
    "\n",
    "model = torch.hub.load(yolo_dir, 'custom', path = weights_path, source='local',force_reload=True)\n",
    "\n",
    "for video in buoy_vids:\n",
    "\n",
    "    # path to images\n",
    "    img_dir = os.path.join(annotated_dir, video + images)\n",
    "    img_filenames=os.listdir(img_dir)\n",
    "    img_filenames.sort() # put them in chronological order\n",
    "\n",
    "    # path to save inference dir\n",
    "    inf_dir = os.path.join(annotated_dir, video, inference)\n",
    "\n",
    "    # gt path\n",
    "    gt_lbl_dir = os.path.join(annotated_dir, video, labels)\n",
    "\n",
    " \n",
    "\n",
    "    for sz in img_sz: #f or every img size we want to run inference at\n",
    "        # make a new folder within the inference folder for each image size\n",
    "        imgsz_dir = 'imgsz' + str(sz)\n",
    "        img_save_dir = os.path.join(inf_dir, imgsz_dir)\n",
    "        save_json_path = os.path.join(img_save_dir, 'inference_results.json')\n",
    "        output_stats = {}\n",
    "\n",
    "        for file in img_filenames:\n",
    "            # run inference\n",
    "            img_path = os.path.join(img_dir, file)\n",
    "            results = model(img_path, size= sz)\n",
    "            results.save(labels=True, save_dir=img_save_dir,exist_ok =True) #exist_ok will rewrite existing folders instead of creating a new one so beware !\n",
    "            \n",
    "            times = list(results.t)\n",
    "            times.append(sum(times)) # times = [prep_t, infer_t, nms_t, total]\n",
    "            detects = results.pandas().xywhn[0]\n",
    "            detects = detects.values.tolist()\n",
    "            _, _, img_w, img_h = results.s\n",
    "\n",
    "            frame_num = cf.imgname2frame(file)\n",
    "            output_stats[file] = {\n",
    "                'Frame': frame_num,\n",
    "                'Img Dimensions': [sz, img_w, img_h],\n",
    "                'Time Stats': times,\n",
    "                'Detections': detects\n",
    "                \n",
    "            }\n",
    "        \n",
    "        # save stats \n",
    "        with open(save_json_path,'w') as json_file:\n",
    "            json.dump(output_stats,json_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Comparing inference results to ground truth (manually annotated) labels \n",
    "Labels validated by boundary box IOU, and does not take into account correct class prediction. Correct labels will be saved to another json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define minimum IOU threshold\n",
    "miniou = 0.2\n",
    "\n",
    "for video in buoy_vids:\n",
    "    inf_dir = os.path.join(annotated_dir, video, inference)\n",
    "    \n",
    "    for sz in img_sz:\n",
    "\n",
    "        pred_json = os.path.join(inf_dir,  'imgsz' + str(sz), 'inference_results.json')  \n",
    "        \n",
    "        files = os.listdir(gt_lbl_dir)\n",
    "        files.sort()\n",
    "        correct = [] \n",
    "        incorrect = []\n",
    "        validated={}\n",
    "\n",
    "        with open(pred_json, 'r') as jsonfile:\n",
    "            pred_data = json.load(jsonfile)\n",
    "    \n",
    "        for img_name in img_filenames: \n",
    "            frame_num = cf.imgname2frame(img_name)\n",
    "            gt_lbl_path = os.path.join(gt_lbl_dir, img_name[:-4] + '.txt')\n",
    "            gt_labels = cf.load_labels(gt_lbl_path)\n",
    "            if gt_labels: #if theres an object in the img\n",
    "                ## inf = cf.Inference(pred_data[img_name]) #inference data for that img\n",
    "                inf = pred_data[img_name]\n",
    "                if inf['Detections xywhn:']: # if the model detected something\n",
    "                    detects = inf['Detections xywhn:']\n",
    "                    # do iou for between all labels\n",
    "                    for i in range(0,len(gt_labels)):\n",
    "                        gt_xywhn = gt_labels[i][1:]\n",
    "                        for detect in detects:\n",
    "                            d_xywhn = detect[0:4]\n",
    "\n",
    "                            # do iou\n",
    "                            if cf.compare_labels(gt_xywhn,d_xywhn, miniou): # compare labels returns false if boxes don't line up\n",
    "                                validated[img_name] = inf\n",
    "                                correct.append(img_name)\n",
    "                            else:\n",
    "                                incorrect.append(img_name)\n",
    "\n",
    "        save_json_path = inf_dir +  'imgsz' + str(sz) + '/validated_results.json'\n",
    "        with open(save_json_path,'w') as json_file:\n",
    "            json.dump(validated,json_file)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Plot the house down boots !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in range(0,len(buoy_vids)):\n",
    "    video = buoy_vids[q]\n",
    "    inf_dir = os.path.join(annotated_dir, video, inference)\n",
    "    csvpath = os.path.join(annotated_dir, video, 'frames_dist_corr.csv')\n",
    "    plot_save_path = os.path.join(inf_dir, video + plot_save_name)\n",
    "    frames, dists = cf.frames2distances(csvpath) # get the interpolated dist for each frame num\n",
    "    figure, axis = plt.subplots(len(img_sz), 1, figsize=(12,10), sharex=True, sharey=True)\n",
    "\n",
    "    for i in range(0,len(img_sz)):\n",
    "\n",
    "        validated_path = os.path.join(inf_dir, 'imgsz' + str(img_sz[i]), 'validated_results.json' )   \n",
    "        # plot validated results for all the frames in the frames array\n",
    "\n",
    "        with open(validated_path, 'r') as jsonfile:\n",
    "                val_data = json.load(jsonfile) \n",
    "        conf = np.empty((0,len(frames)))\n",
    "        times = np.empty((0,len(frames)))\n",
    "        clss = np.empty((0,len(frames)))\n",
    "\n",
    "        for j in frames:\n",
    "            #make file name\n",
    "            img_name = 'frame_' + str(f\"{j:05d}\") + '.png'\n",
    "            try:\n",
    "                det = val_data[img_name]['Detections']\n",
    "                c = det[0][4]\n",
    "                conf = np.append(conf, c)\n",
    "\n",
    "                id = det[0][5]\n",
    "                clss = np.append(clss, id)\n",
    "\n",
    "                t = val_data[img_name]['Time Stats']\n",
    "                total_t = t[3]\n",
    "                times = np.append(times,total_t)\n",
    "\n",
    "            except KeyError:\n",
    "                #print(f\"{img_name} did not have a detection in it\")\n",
    "                conf = np.append(conf, np.nan)\n",
    "                times = np.append(times, np.nan)\n",
    "                clss = np.append(clss, -1)\n",
    "\n",
    "        color_map = {0: 'limegreen', 1: 'magenta', 2: 'royalblue', -1:'white'}\n",
    "        colors = np.array([color_map[val] for val in clss])\n",
    "\n",
    "        avg_t = np.nanmean(times)\n",
    "        axis[i].scatter(dists,conf,s=2, c=colors)\n",
    "        axis[i].grid(True, which='both', linestyle='--', color='gray', linewidth=0.5,alpha=0.5)\n",
    "        axis[i].invert_xaxis()\n",
    "        axis[i].set_ylim(0,1.0)\n",
    "        axis[i].set_xlim(100,4)\n",
    "        axis[i].set_yticks([0, 0.25, 0.5, 0.75, 1])\n",
    "        axis[i].set_xticks(np.linspace(100,5,20))\n",
    "        axis[i].set_title(f\"Input Size = {img_sz[i]},\" + r'  $\\bar{t} = $'+ f\"{avg_t:.2f} ms\", fontsize = 10) \n",
    "        #axis[i].text(0.01, 0.95, f'Avg. t = {avg_t:.2f} ms', transform= axis[i].transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left')\n",
    "\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor='limegreen', markersize=10, label='0: navBuoy'),\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor='magenta', markersize=10, label='1: mooringBall'),\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor='royalblue', markersize=10, label='2: fishingBuoy')\n",
    "    ]\n",
    "\n",
    "    # Add the legend to the plot\n",
    "    title = plot_titles[q]\n",
    "    figure.suptitle(f'Detection of {title} at Different Compression Sizes', fontsize=18, y=0.96)\n",
    "    figure.text(0.5, 0.03, 'Buoy Distance from Camera', ha='center', va='center', fontsize=18)\n",
    "    figure.text(0.03, 0.5, 'Confidence', ha='center', va='center', rotation='vertical', fontsize=18)\n",
    "    figure.legend(handles=legend_elements, loc='center', ncol=3, bbox_to_anchor=(0.5, 0.91))\n",
    "    plt.tight_layout(rect=[0.04, 0.04, 0.95, 0.95])  \n",
    "    \n",
    "    figure.savefig(plot_save_path, dpi=400)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
